# 31. Метод k-средних: основной алгоритм; вариации метода. Особенности метода. Подбор оптимального числа кластеров с помощью Inertia. [[⇧]](../questions-list.md)

## Алгоритм:

1. Выбор начальных положений центроидов $μ_1, μ_2, \ldots , μ_k$.
2. Повтор пока $x_i$ не перестанет изменяться:  
   2.1.**Кластеризация** (отнести каждый объект к кластеру ближайшего к нему центроида):
   $$y_i =argmin ||x_i -μ_y || \quad i=1,2,…,l$$
   2.2. **Обновление центроидов** (пересчитать координаты центроидов как центры масс только что построенных кластеров):
   $$μ_y = \frac{∑^l_{i=1}[y_i =y] \cdot x_i }{∑^l_{i=1}[y_i =y]}, y∈Y$$

### Вариации

- **R-means Болла-Холла**. Начальные положения центроидов определяются случайным образом; в другом варианте (в случае 2-х кластеров) – наиболее удалённые друг от друга объекты
- **R-mean МакКина**. Координаты центроидов пересчитываются при каждом переходе объекта из кластера в кластер.
- **Mini Batch k-means**. Вычисление среднего арифметического на шаге 2.2 не по все объектам, а по объектам некоторой случайной подвыборки.
- **K-means++**. Начальные координаты центроидов выбираются более оптимальным образом: положение первого центроида – случайно из равномерного распределения на выборке, на каждый следующий центроид из оставшихся точек так, чтобы вероятность выбрать каждую точку была пропорциональна квадрату расстояния от нее до ближайшего центра.

## Особенности метода k-means

- Функционал, который минимизирует метод не гарантирует достижение **глобального** минимума $f_0$, а только одного из его локальных минимумов.
- Алгоритм **крайне чувствителен** к выбору начальных приближений центров кластеров. Случайная инициализация центров на шаге 1 может приводить к плохим результатам
- Кластеризация может оказаться **неадекватной**, если изначально задано неверное количество кластеров.
