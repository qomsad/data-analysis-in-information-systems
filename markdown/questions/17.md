# 17. Метрики качества алгоритмов в задачах бинарной классификации. Типы ошибок, матрица ошибок. Учет возможного дисбаланса классов и разной цены ошибок. [[⇧]](../questions-list.md)

## Доля неправильных ответов

$$
errorRate(a, X) = \frac{1}{n} ∑_{i=1}^{n}[a(x_i) \ne y_i]
$$

> Но в задачах классификации принято выбирать метрику так, чтобы её нужно было **максимизировать**.

## Доля правильных ответов

$$
accuracy(a,X) = \frac{1}{n} ∑_{i=1}^{n}[a(x_i) = y_i]
$$

## Типы ошибок, матрица ошибок

### Матрица ошибок

$a(x)=1$ алгоритм **сработал** на объекте:

- **Верное срабатывание**, если объект действительно относится к классу $+1$.
- **Ложное срабатывание**, если объект принадлежит к классу $-1$.

$a(x)=-1$ алгоритм **пропускает** объект:

- **Истинный пропуск**, если объект действительно относится к классу $-1$.
- **Ложный пропуск**, если объект принадлежит к классу $+1$.

|             | $y= +1$                                   | $y= -1$                                   |
| ----------- | ----------------------------------------- | ----------------------------------------- |
| $a(x) = +1$ | $\textcolor{green}{True\ Positive\ (TP)}$ | $\textcolor{red}{False\ Positive\ (FP)}$  |
| $a(x) = -1$ | $\textcolor{red}{False\ Negative\ (FN)}$  | $\textcolor{green}{True\ Negative\ (TN)}$ |

### Типы ошибок

- Ложное срабатывание
- Ложный пропуск

### Точность

$$
precision(a,X) = \frac{TP}{TP + FP}
$$

### Полнота

$$
recall(a,X) = \frac{TP}{TP + FN}
$$

### Объединение точности и полноты

Во многих случаях требуется не условная оптимизация одного из показателей точности или полноты, ы высокие оценки обоих показателей одновременно.

Необходимо объединить показатели в **одну** метрику качества.

#### Арифметическое среднее

$$
A = \frac{precision + recall}{2}
$$

#### Минимум

$$
M =\min(precision, recall)
$$

#### $F$-мера

$$
F = \frac{2 \cdot precision \cdot recall}{precision + recall}
$$

#### Расширенная $F$-мера

$$
F_{\beta} = \frac{(1 + \beta^2) \cdot precision \cdot recall}{\beta^2 \cdot precision + recall}
$$

$\beta$ – **приоритет** точности или полноты, $\beta < 1$ увеличивается вклад **полноты**, $\beta > 1$ увеличивается вклад **точности**.

### Учет возможного дисбаланса классов и разной цены ошибок

1. **Несбалансированные выборки**. В случае несбалансированных данных значение accuracy не позволяет адекватно оценить качество алгоритмов. Для решения проблемы несбалансированной выборки. Пусть $q_0$ – доля объектов самого крупного класса в выборке, тогда алгоритм разумный, если $accuracy \in [q_0, 1]$
2. **Цена ошибки**. Метрика $accuracy$ не учитывает, что разные типы ошибок могут иметь разную цену
