# 19. Многоклассовая классификация: постановка задачи, подход ONE-VS-ALL, метрики качества алгоритмов. Методы работы с несбалансированными выборками. [[⇧]](../questions-list.md)

## Пространство ответов

В задаче многоклассовой классификации всего $k$ классов объектов:

$$
\mathcal{Y} = \lbrace 1, 2, 3, \ldots, k \rbrace
$$

## Подход ONE-VS-ALL

Подход **один против всех** — для каждого класса строится свой **бинарный** классификатор, задача которого, отделение данного класса от всех остальных.

### Формальная постановка задачи

- Задача сводится к решению $k$ задач бинарной классификации.
- $k$-я задача анализирует выборку:
  $$X = (x_i, [y_i = k])_{i=1}^n$$

  > Объекты те же, что и в исходной выборке, а ответы бинарные.

- Формирует алгоритм, который отделяет $k$-й класс от остальных:
  $$a_k(x) = sign \langle w_k, x \rangle$$

Для построение многоклассового классификатора разумно использовать следующий алгоритм:

$$
a(x) = \argmax_{k \in {\lbrace 1, 2, 3, \ldots, k \rbrace}} |\langle w_k, x \rangle|
$$

$|\langle w_k, x \rangle|$ – абсолютная величина скалярного произведения, характеризует степень **«уверенности»** классификатора в своем ответе.

$\argmax_{k}(x)$ – максимальное значения функции $x$ для множества $k$.

## Метрики качества алгоритмов

### Доля правильных ответов

$$
accuracy(a,X) = \frac{1}{n} ∑_{i=1}^{n}[a(x_i) = y_i]
$$

### Матрица ошибок

$a(x)=t_{\in \mathcal{Y}}$ алгоритм **сработал** на объекте:

- **Верное срабатывание** $TP_t$, если объект действительно **относится** к классу $t$.
- **Ложное срабатывание** $FP_t$, если объект принадлежит к классу $t$.

$a(x)\ne t_{\in \mathcal{Y}}$ алгоритм **пропускает** объект:

- **Истинный пропуск** $TN_t$, если объект действительно **не относится** к классу $t$.
- **Ложный пропуск** $FN_t$, если объект принадлежит к классу $t$.

|            | $y= 1$   | $y= 2$   | $\ldots$ | $y =k$   |
| ---------- | -------- | -------- | -------- | -------- |
| $a(x) = 1$ | $q_{11}$ | $q_{12}$ | $\ldots$ | $q_{1k}$ |
| $a(x) = 2$ | $q_{21}$ | $q_{22}$ | $\ldots$ | $q_{2k}$ |
| $\ldots$   | $\ldots$ | $\ldots$ | $\ldots$ | $\ldots$ |
| $a(x)=k$   | $q_{k1}$ | $q_{k2}$ | $\ldots$ | $q_{kk}$ |

$q_{ij}$ – количество объектов $j$-го класса, которые алгоритм отнес к $i$-му классу.

> Матрица ошибок позволяет выявить, в каких именно классах чаще всего допускаются ошибки классификации.

### Точность по классу

$$
precision(a,X,t) = \frac{∑_{y}TP_t}{∑_{y}(TP_t + FP_t)}
$$

### Полнота по классу

$$
recall(a,X,t) = \frac{∑_{y}TP_t}{∑_{y}(TP_t + FN_t)}
$$

### Среднее значение точности по всем классам

$$
\overline{precision(a,X)} = ∑_{t=1}^{k}precision(a,X,t)
$$

### Среднее значение полноты по всем классам

$$
\overline{recall(a,X)} = ∑_{t=1}^{k}recall(a,X,t)
$$

### Средняя $F$-мера по всем классам

$$
F = \frac{2 \cdot \overline{precision(a,X)} \cdot \overline{recall(a,X)}}{\overline{precision(a,X)} + \overline{recall(a,X)}}
$$

## Проблема несбалансированности выборки

`Пусть:` решается задача классификации.

Задача называется **несбалансированной**, если объектов одного класса существенно меньше, чем объектов остальных классов.

`Проблема:` классификаторы **минимизируют** число неправильных ответов, если цена ошибки в каждом классе одинакова, то может оказаться выгоднее отнести все объекты к **большему классу**.

`Решение:`

- **Undersampling** — уравнивание размеров классов за счет **удаления** из выборки части объектов, относящихся к многочисленным классам.
- **Oversampling** — Уравнивание размеров классов за счет **дублирования** объектов, относящихся к маленьким классам.
