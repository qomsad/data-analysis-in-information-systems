# 26. Разложение ошибки алгоритма машинного обучения. Смещение и разброс композиции алгоритмов; подходы к уменьшению корреляции базовых алгоритмов. [[⇧]](../questions-list.md)

## Разложение ошибки алгоритма машинного обучения

**Ошибка алгоритма** на тестовых данных складывается из трех компонент, которые характеризуют разные аспекты данных и модели:

$$L(a) = \textit{Шум} + \textit{Смещение} + \textit{Разброс}$$

### Шум

**Шум** $noise$ — характеристика **данных**, проявляется в **сложности** и **противоречивости**.

$$
M_{x,y}\Big((y - M(y|x)^2)\Big)
$$

Шум показывает **ожидаемую** ошибку для идеального алгоритма.

> Проявляется для любой модели.

### Смещение

**Смешение** $bias$ — характеризует отклонение усредненного по различным обучающим выборкам прогноза данной модели от прогноза идеальной модели:

$$
M_x\Big(\big(M_x(a(X))\big) - M(y|x)^2\Big)
$$

### Разброс

**Разброс** $variance$ — дисперсия ответов моделей, обученных на различных обучающих выборках:

$$
M_x\Big(M_x\big( a(X) - M_x(a(X))\big)^2\Big)
$$

> Разброс характеризует устойчивость модели к изменениям в обучающей выборке.

### Смещение и разброс

- **Линейные** модели:
  - Высокое смешение если истинная зависимость линейной не является.
  - Низкий разброс, так как у алгоритма мало параметров.
- Решающие **деревья**:
  - Низкое смешение, способны восстанавливать сложные зависимости.
  - Высокий разброс, сильные изменения даже при небольших изменениях обучающей выборки.

## Подходы к уменьшению корреляции базовых алгоритмов

- **Begging** $=$ **B**ootstrap **agg**regat**ing** — обучение на случайных подвыборках исходной.
- **Метод случайных подпространств** — случайное подмножество признаков из исходной выборки.
