# 21. Общая характеристика решающих деревьев: структура, вид разделяющей поверхности в задаче классификации, вид восстановленной зависимости в задаче регрессии, возможность переобучения. [[⇧]](../questions-list.md)

## Решающие деревья

- Бинарные деревья (чаще всего).
- В каждой внутренней вершине дерева записано **условие**, в каждом листе — **прогноз**.
- Условия чаще всего выбираются простые. Самый распространенный вариант — сравнение значения некоторого признака с заданным **порогом**: $[x^j \le t]$
- **Прогноз** в листе:
  - Действительное число, если решается задача регрессии.
  - Метка класс (и/или вероятность принадлежности классу), если решается задача классификации.

## Вид разделяющей поверхности в задаче классификации

Решающие деревья позволяют **разделить** линейно не разделимые классы.

Разделяющая поверхность каждого класса **кусочно-постоянная**: каждая линия раздела параллельна оси координат.

> С помощью решающего дерева **можно идеально разделить любую выборку**, в случае если нет противоречий (объектов с одинаковыми признаками но разными ответами).

## Вид восстановленной зависимости в задаче регрессии

Зависимость целевой переменной от признаков описывается **кусочно-постоянной** функцией.

## Возможность переобучения в случае классификации

Решающее дерево можно сделать настолько **глубоким**, что каждый лист будет соответствовать ровно одному объекту обучающей выборки. В этом случае на обучающей выборке получается **нулевая ошибка**. При этом оно будет сильно **переобученным**, и на тестовой выборке покажет плохие результаты.

**Вывод**: имеет смысл искать минимальное в некотором смысле (например, с минимальным числом листьев) дерево из имеющих нулевую ошибку.

> Hо: эта задача NP-полная (невозможно решить за разумное время).А
