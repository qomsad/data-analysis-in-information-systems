# 14. Регуляризация линейной модели машинного обучения (основная идея). Типы регуляризаторов, особенности каждого типа. [[⇧]](../questions-list.md)

## Регуляризация линейной модели машинного обучения

Возможное **решение проблемы переобучения** — ввести штраф за большие веса.

Идея **регуляризации** линейной модели — минимизировать не саму функцию ошибки $Q(w,X)$, а новую функцию, полученную добавлением **регуляризатора**.

## Типы регуляризаторов, особенности каждого типа

### Квадратичный регуляризатор $L_2$

$$
Q^{*}(w, X) = Q(w, X) + \lambda ||w||^2
$$

$\lambda$ – коэффициент регуляризации

**Новая** задача минимизации:

$$
Q^{*}(w, X) = \frac{1}{n}∑_{i=1}^{n}(\langle w, x_i \rangle - y_i)^2 + \lambda ||w||^2 \to \min_{w}
$$

#### Коэффициент регуляризации

- Чем больше значение $\lambda$, тем ниже сложность модели — риск **недообучения** (при очень больших значениях $\lambda$, может оказаться оптимальным просто занулить веса).
- Чем меньше значение $\lambda$, тем выше сложность модели — риск **переобучения**.

**Требуется баланс** — значение $\lambda$ достаточно большое, чтобы не допустить переобучения, но не слишком большое, чтобы уловить закономерности в данных.

Задача минимизации **эквивалентна** задаче:

$$
\begin{cases}
\lbrace  Q(w,X) \to \min \\
 ||w||^2 \le C \end{cases}
$$

$C$ – некоторая константа.

**Важное свойство** $L_2$ регуляризатора: в результате получается **гладкая выпуклая** функция — применим метод градиентного спуска.

### $L_1$-регуляризатор

$$
Q^{*}(w, X) = Q(w, X) + \lambda ||w||
$$

$\lambda$ – коэффициент регуляризации

**Новая** задача минимизации:

$$
Q^{*}(w, X) = \frac{1}{n}∑_{i=1}^{n}(\langle w, x_i \rangle - y_i)^2 + \lambda ||w|| \to \min_{w}
$$

Свойства $L_1$-регуляризатора:

- **Не является гладкой функцией** — нельзя применять градиентные методы.
- После применения некоторые веса становятся равными нулю (близкими к нулю) — $L_1$-регуляризатор позволяет выполнить отбор наиболее **значимых** признаков.

Если признаки масштабированы[^1], то величина веса соответствует значимости признака.

> Лучший способ оценки важности признака — **удалить** этот признак из модели и проследить за **увеличением ошибки** алгоритма.

[^1]:
    Масштабирование признаков — приведение признаков к одному масштабу, помещение признаков в один диапазон:  
    **Стандартизация** — преобразование данных, чтобы получить среднее значение равное нулю, и стандартное отклонение равное единице.  
    **Нормализация** — сопоставление минимального значение признака равным нулю, максимального – единице, следовательно значения признаков отображаются в диапазон от нуля до единицы.
